import os
import re
from decimal import Decimal, ROUND_UP
from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template, redirect, url_for, flash, session
from flask_login import LoginManager, login_user, logout_user, login_required, current_user
from authlib.integrations.flask_client import OAuth

# --- AI IMPORTS ---
from langchain_openai import ChatOpenAI
from langchain_groq import ChatGroq
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.checkpoint.postgres import PostgresSaver
from psycopg_pool import ConnectionPool
from typing import TypedDict, Annotated, List
import operator

# --- DATABASE MODELS ---
from models import db, User

# --- SETUP ---
load_dotenv()
app = Flask(__name__, template_folder='templates')

# --- CONFIG ---
app.config['SECRET_KEY'] = os.environ.get('FLASK_SECRET_KEY')
app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL')
app.config['YOUR_DOMAIN'] = os.environ.get('YOUR_DOMAIN')
app.config['SESSION_COOKIE_SECURE'] = False
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'

# Auth0
app.config['AUTH0_CLIENT_ID'] = os.environ.get('AUTH0_CLIENT_ID')
app.config['AUTH0_CLIENT_SECRET'] = os.environ.get('AUTH0_CLIENT_SECRET')
app.config['AUTH0_DOMAIN'] = os.environ.get('AUTH0_DOMAIN')

db.init_app(app)

# --- LOGIN MANAGER ---
login_manager = LoginManager()
login_manager.login_view = 'login'
login_manager.init_app(app)

@login_manager.user_loader
def load_user(user_id):
    return db.session.get(User, int(user_id))

# --- OAUTH ---
oauth = OAuth(app)
auth0 = oauth.register(
    'auth0',
    client_id=app.config['AUTH0_CLIENT_ID'],
    client_secret=app.config['AUTH0_CLIENT_SECRET'],
    api_base_url=f"https://{app.config['AUTH0_DOMAIN']}",
    access_token_url=f"https://{app.config['AUTH0_DOMAIN']}/oauth/token",
    authorize_url=f"https://{app.config['AUTH0_DOMAIN']}/authorize",
    client_kwargs={'scope': 'openid profile email'},
    server_metadata_url=f"https://{app.config['AUTH0_DOMAIN']}/.well-known/openid-configuration"
)

# ==============================================================================
# 1. INITIALIZE THE "EMPLOYEES" (AI MODELS)
# ==============================================================================

try:
    # 1. THE RECEPTIONIST & BACKEND WORKER (Fast & Free)
    # Used for routing and backend code generation.
    groq_llm = ChatGroq(
        model_name='llama-3.3-70b-versatile', 
        api_key=os.environ.get('GROQ_API_KEY')
    )

    # 2. THE CEO (Smartest & Expensive)
    # Used for the "Brain" to plan and review.
    gpt4o_llm = ChatOpenAI(
        model='gpt-4o', 
        api_key=os.environ.get('OPENAI_API_KEY')
    )

    # 3. THE UI DESIGNER (Efficient & Cheap)
    # Used for UI, HTML, CSS tasks.
    gpt4o_mini_llm = ChatOpenAI(
        model='gpt-4o-mini', 
        api_key=os.environ.get('OPENAI_API_KEY')
    )

except Exception as e:
    print(f"CRITICAL: AI Clients failed to load. {e}")

# ==============================================================================
# 2. DEFINE THE TOOLS (THE SPECIALISTS)
# ==============================================================================

@tool
def ui_builder_tool(prompt: str) -> str:
    """
    Use this tool to generate HTML, CSS, React, or Frontend code.
    Delegates to the UI Specialist (GPT-4o-mini).
    """
    messages = [
        SystemMessage(content="You are an expert Frontend Developer. Generate clean, modern HTML/Tailwind code."),
        HumanMessage(content=prompt)
    ]
    response = gpt4o_mini_llm.invoke(messages)
    
    # Return the code along with metadata for cost tracking
    return f"[UI Generated by GPT-4o-mini] TokenUsage: {response.response_metadata.get('token_usage')} \n\n {response.content}"

@tool
def backend_builder_tool(prompt: str) -> str:
    """
    Use this tool to generate Python, Flask, SQL, or complex Backend logic.
    Delegates to the Backend Specialist (Groq Llama 3.3).
    """
    messages = [
        SystemMessage(content="You are a Senior Backend Engineer. Write secure, production-ready Python code."),
        HumanMessage(content=prompt)
    ]
    # Using Groq here (Free alternative to DeepSeek)
    response = groq_llm.invoke(messages)
    
    return f"[Backend Generated by Llama 3.3] TokenUsage: {response.response_metadata.get('token_usage')} \n\n {response.content}"

@tool
def web_search_tool(query: str) -> str:
    """
    Use this tool to find real-time information, news, weather, or current events.
    """
    search = DuckDuckGoSearchRun()
    return search.invoke(query)

# ==============================================================================
# 3. BUILD THE AGENT (THE BRAIN)
# ==============================================================================

# The Boss (GPT-4o) gets access to the tools
tools = [ui_builder_tool, backend_builder_tool, web_search_tool]
agent_brain = gpt4o_llm.bind_tools(tools)

# Define State
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]

# Node 1: The Brain decides what to do
def brain_node(state):
    return {"messages": [agent_brain.invoke(state["messages"])]}

# Node 2: The Tool Execution Node
def tool_node(state):
    last_message = state["messages"][-1]
    tool_calls = last_message.tool_calls
    results = []
    
    for t in tool_calls:
        # Find the matching tool function
        selected_tool = {
            "ui_builder_tool": ui_builder_tool,
            "backend_builder_tool": backend_builder_tool,
            "web_search_tool": web_search_tool
        }.get(t["name"])
        
        if selected_tool:
            # Run the tool
            output = selected_tool.invoke(t["args"])
            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(output)))
            
    return {"messages": results}

# Logic: Should we stop or run tools?
def should_continue(state):
    last_message = state["messages"][-1]
    if last_message.tool_calls:
        return "tools"
    return END

# Compile the Graph
workflow = StateGraph(AgentState)
workflow.add_node("brain", brain_node)
workflow.add_node("tools", tool_node)
workflow.set_entry_point("brain")
workflow.add_conditional_edges("brain", should_continue, {"tools": "tools", END: END})
workflow.add_edge("tools", "brain")

# Setup Database Checkpointer (Memory)
db_url = os.environ.get("DATABASE_URL")
if db_url and db_url.startswith("postgresql"):
    pool = ConnectionPool(conninfo=db_url, max_size=20, kwargs={"autocommit": True})
    memory = PostgresSaver(pool)
    with app.app_context(), memory as m:
        m.setup()
else:
    memory = SqliteSaver.from_conn_string("checkpoints.sqlite")

agent_app = workflow.compile(checkpointer=memory)

# ==============================================================================
# 4. PRICING CALCULATOR
# ==============================================================================

PRICING = {
    'gpt-4o': {'in': Decimal('2.50'), 'out': Decimal('10.00')},      # Expensive
    'gpt-4o-mini': {'in': Decimal('0.15'), 'out': Decimal('0.60')},  # Cheap
    'llama-3.3-70b-versatile': {'in': Decimal('0.00'), 'out': Decimal('0.00')}, # Free
}

def calculate_cost(model, input_tok, output_tok):
    if model not in PRICING: return Decimal('0.0')
    p = PRICING[model]
    cost = (Decimal(input_tok)/1000000 * p['in']) + (Decimal(output_tok)/1000000 * p['out'])
    # Convert USD to Credits (e.g., 1 Credit = $0.01 USD approx)
    return cost * Decimal('100') 

# ==============================================================================
# 5. API ENDPOINTS
# ==============================================================================

def simple_chat(prompt):
    """Direct chat with Groq (Fast/Free)"""
    return groq_llm.invoke([HumanMessage(content=prompt)]).content

@app.route("/api/ask", methods=["POST"])
@login_required
def handle_ask():
    user_prompt = request.json.get("prompt")
    user_id = current_user.auth0_id
    total_credits = Decimal('0.0')

    # --- STEP 1: ROUTING (The Receptionist) ---
    # We use Groq (Llama 3.3) to classify because it's free and fast.
    router_system = """
    Classify this prompt into one category:
    1. 'simple': Greetings, jokes, general knowledge (e.g., "What is Excel?", "Explain photosynthesis").
    2. 'complex': Requests for code, weather, news, analysis, or multi-step tasks.
    Return ONLY the word 'simple' or 'complex'.
    """
    try:
        classification = groq_llm.invoke([
            SystemMessage(content=router_system), 
            HumanMessage(content=user_prompt)
        ]).content.strip().lower()
    except:
        classification = 'complex' # Fallback to smart agent if router fails

    final_response = ""

    # --- STEP 2: EXECUTION ---
    
    if "simple" in classification:
        # Use Groq for free chat
        final_response = simple_chat(user_prompt)
        # Cost is 0 for Groq
    else:
        # Use the Agency (GPT-4o Brain)
        config = {"configurable": {"thread_id": user_id}}
        result = agent_app.invoke(
            {"messages": [HumanMessage(content=user_prompt)]}, 
            config=config
        )
        final_response = result["messages"][-1].content
        
        # --- STEP 3: COST CALCULATION (Estimated) ---
        # We estimate cost based on the Brain (GPT-4o) usage.
        # In a production app, you'd parse token usage from the response metadata.
        # Estimate: 500 input tokens + response length for output
        total_credits += calculate_cost('gpt-4o', 500, len(final_response)/4)

    # Deduct credits
    if current_user.get_credit_balance() < total_credits:
         return jsonify({"error": "Insufficient credits"}), 402
         
    current_user.credits -= total_credits
    db.session.commit()

    return jsonify({
        "answer": final_response,
        "cost": float(total_credits),
        "remaining": float(current_user.credits)
    })

# --- STANDARD ROUTES ---
@app.route('/')
def index():
    if current_user.is_authenticated: return redirect(url_for('chat_interface'))
    return render_template('landing.html')

@app.route('/app')
@login_required
def chat_interface():
    return render_template('ai_assistant.html', user_credits=current_user.get_credit_balance())

@app.route('/login')
def login(): return oauth.auth0.authorize_redirect(redirect_uri=url_for('callback', _external=True))

@app.route('/signup')
def signup(): return oauth.auth0.authorize_redirect(redirect_uri=url_for('callback', _external=True), screen_hint='signup')

@app.route('/callback')
def callback():
    try:
        token = oauth.auth0.authorize_access_token()
        user_info = auth0.get('userinfo').json()
        auth0_id = user_info.get('sub')
        email = user_info.get('email')
        
        user = User.query.filter_by(auth0_id=auth0_id).first()
        if not user:
            user = User(auth0_id=auth0_id, email=email, credits=Decimal('50.0')) # 50 Free credits
            db.session.add(user)
            db.session.commit()
        
        login_user(user, remember=True)
        return redirect(url_for('chat_interface'))
    except Exception as e:
        print(f"Error during callback: {e}")
        return redirect(url_for('index'))

@app.route('/logout')
def logout():
    session.clear()
    logout_user()
    return redirect(f"https://{app.config['AUTH0_DOMAIN']}/v2/logout?client_id={app.config['AUTH0_CLIENT_ID']}&returnTo={url_for('index', _external=True)}")

if __name__ == "__main__":
    with app.app_context(): db.create_all()
    app.run(host='0.0.0.0', port=5000, debug=True)